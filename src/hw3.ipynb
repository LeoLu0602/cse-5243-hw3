{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc8bbee-618f-46ab-85ea-e4325e4a0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# converts a txt file to the form of [string, int][]\n",
    "def clean(path):\n",
    "    res = []\n",
    "    \n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            words = line.split()\n",
    "            # remove all leading and trailing nonalphabetic characters in each word and transform into lowercase\n",
    "            # ex: -I'm, -> i'm\n",
    "            sentence = ' '.join([re.sub(r'^[^a-zA-Z]+|[^a-zA-Z]+$','' , word).lower() for word in words[:-1]])\n",
    "            label = int(words[-1])\n",
    "            res.append([sentence, label])\n",
    "\n",
    "    return res\n",
    "\n",
    "# gives each word an unique number (starting from 0)\n",
    "def encode(words):\n",
    "    res = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in res:\n",
    "            res[word] = len(res)\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "def construct_matrix(sentences, word2num):\n",
    "    M = len(sentences)\n",
    "    N = len(word2num)\n",
    "    res = [[0] * N for i in range(M)]\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in sentence.split():\n",
    "            res[i][word2num[word]] += 1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239d23cb-f99f-451e-9670-11bb1711b716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "['a very very very slow-moving aimless movie about a distressed drifting young man', 0]\n"
     ]
    }
   ],
   "source": [
    "# get all txt files under ./data except for readme.txt\n",
    "FILES = [os.path.join('./data', f) for f in os.listdir('./data') if f.endswith('.txt') and f != 'readme.txt']\n",
    "data = []\n",
    "\n",
    "for file in FILES:\n",
    "    data += clean(file)\n",
    "\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03fb9bc-511d-48dd-ab47-4f71e6c0aac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5339\n",
      "[('a', 0), ('very', 1), ('slow-moving', 2), ('aimless', 3), ('movie', 4)]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for x in data:\n",
    "    for word in x[0].split():\n",
    "        words.append(word)\n",
    "\n",
    "word2num = encode(words)\n",
    "\n",
    "print(len(word2num))\n",
    "print([(word, num) for word, num in word2num.items() if num < 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14f0214-fe35-443b-97c2-4b5102df0bba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 5339\n",
      "[2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "D = construct_matrix([x[0] for x in data], word2num)\n",
    "\n",
    "print(len(D), len(D[0]))\n",
    "print(D[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ccdf508-ffff-4ea8-a1c8-b7f4c220925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[886 243   1   1 177  85   1   1   4  14]\n"
     ]
    }
   ],
   "source": [
    "# HW3 starts here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "col_sums = np.sum(np.array(D), axis=0)\n",
    "print(col_sums[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf883bd-e5e3-45c6-ac2a-01651cfe67c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['off', 'before', 'd', 'then', \"it's\", 'all', 'into', \"you'll\", 'them', 'once']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kennycartman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "print(list(STOP_WORDS)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075b2282-bde1-46d3-b04a-6360956bf5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16  32  77   0  57  50  75 117  23  13]\n"
     ]
    }
   ],
   "source": [
    "words_sorted_by_freq = np.argsort(col_sums)[::-1] # descending order\n",
    "print(words_sorted_by_freq[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab76e2be-e133-44ff-b6f2-d7c5f34f8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5339\n",
      "[(0, 'a'), (1, 'very'), (2, 'slow-moving'), (3, 'aimless'), (4, 'movie'), (5, 'about'), (6, 'distressed'), (7, 'drifting'), (8, 'young'), (9, 'man')]\n"
     ]
    }
   ],
   "source": [
    "num2word = {num: word for word, num in word2num.items()}\n",
    "print(len(num2word))\n",
    "print([(num, word) for num, word in num2word.items() if num < 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f2cb90-eda2-4609-94cc-3470c428a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5195\n",
      "[87, 455, 4, 4412, 147, 231, 3181, 314, 1600, 250]\n",
      "['good', 'great', 'movie', 'phone', 'film', 'one', 'food', 'like', 'place', 'time']\n"
     ]
    }
   ],
   "source": [
    "filtered_words_sorted_by_freq = [int(w) for w in words_sorted_by_freq if num2word[int(w)] not in STOP_WORDS] # remove stop words\n",
    "print(len(filtered_words_sorted_by_freq))\n",
    "print(filtered_words_sorted_by_freq[:10]) # number form\n",
    "print([num2word[w] for w in filtered_words_sorted_by_freq[:10]]) # word form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d254da7-2e44-47d3-9f7c-5a280135b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87, 455, 4, 4412, 147, 231, 3181, 314, 1600, 250]\n",
      "[4, 8, 9, 11, 15, 17, 18, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "K = 1000\n",
    "features = filtered_words_sorted_by_freq[:K]\n",
    "print(features[:10])\n",
    "features.sort()\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c70fd323-14ab-472b-9782-e4e68449baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 1000\n",
      "[177   4  14  16   9   4  35   5   4   9]\n",
      "[1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "D_reduced = np.array(D)[:, features]\n",
    "print(len(D_reduced), len(D_reduced[0]))\n",
    "print(np.sum(np.array(D_reduced), axis=0)[:10])\n",
    "print(D_reduced[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec13397-c2e6-4b5f-aa1b-09d3979c3540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
