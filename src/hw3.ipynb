{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20918e76-b109-494a-8cd1-135d67e6551c",
   "metadata": {},
   "source": [
    "# HW#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc8bbee-618f-46ab-85ea-e4325e4a0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# converts a txt file to the form of [string, int][]\n",
    "def clean(path):\n",
    "    res = []\n",
    "    \n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            words = line.split()\n",
    "            # remove all leading and trailing nonalphabetic characters in each word and transform into lowercase\n",
    "            # ex: -I'm, -> i'm\n",
    "            sentence = ' '.join([re.sub(r'^[^a-zA-Z]+|[^a-zA-Z]+$','' , word).lower() for word in words[:-1]])\n",
    "            label = int(words[-1])\n",
    "            res.append([sentence, label])\n",
    "\n",
    "    return res\n",
    "\n",
    "# gives each word an unique number (starting from 0)\n",
    "def encode(words):\n",
    "    res = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in res:\n",
    "            res[word] = len(res)\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "def construct_matrix(sentences, word2num):\n",
    "    M = len(sentences)\n",
    "    N = len(word2num)\n",
    "    res = [[0] * N for i in range(M)]\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in sentence.split():\n",
    "            res[i][word2num[word]] += 1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239d23cb-f99f-451e-9670-11bb1711b716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "['a very very very slow-moving aimless movie about a distressed drifting young man', 0]\n"
     ]
    }
   ],
   "source": [
    "# get all txt files under ./data except for readme.txt\n",
    "FILES = [os.path.join('./data', f) for f in os.listdir('./data') if f.endswith('.txt') and f != 'readme.txt']\n",
    "data = []\n",
    "\n",
    "for file in FILES:\n",
    "    data += clean(file)\n",
    "\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03fb9bc-511d-48dd-ab47-4f71e6c0aac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5339\n",
      "[('a', 0), ('very', 1), ('slow-moving', 2), ('aimless', 3), ('movie', 4)]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for x in data:\n",
    "    for word in x[0].split():\n",
    "        words.append(word)\n",
    "\n",
    "word2num = encode(words)\n",
    "\n",
    "print(len(word2num))\n",
    "print([(word, num) for word, num in word2num.items() if num < 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14f0214-fe35-443b-97c2-4b5102df0bba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 5339\n",
      "[2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "D = construct_matrix([x[0] for x in data], word2num)\n",
    "\n",
    "print(len(D), len(D[0]))\n",
    "print(D[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04e28f-8a04-4348-8a2b-1c688d55bcec",
   "metadata": {},
   "source": [
    "# HW#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab76e2be-e133-44ff-b6f2-d7c5f34f8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num2word's size: 5339\n",
      "first 5 entries in num2word: [(0, 'a'), (1, 'very'), (2, 'slow-moving'), (3, 'aimless'), (4, 'movie')]\n"
     ]
    }
   ],
   "source": [
    "num2word = {num: word for word, num in word2num.items()}\n",
    "print(f\"num2word's size: {len(num2word)}\")\n",
    "print(f'first 5 entries in num2word: {[(num, word) for num, word in num2word.items() if num < 5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ccdf508-ffff-4ea8-a1c8-b7f4c220925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 columns sums in D: [886 243   1   1 177]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "col_sums = np.sum(D, axis=0)\n",
    "print(f'first 5 columns sums in D: {col_sums[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf883bd-e5e3-45c6-ac2a-01651cfe67c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 stop words: ['o' 'is' 'his' 'theirs' 'were']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kennycartman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "print(f'5 stop words: {np.array(list(STOP_WORDS))[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "518f9b45-d3a0-44bf-b6f7-60df899d1d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words after removing stop words: 5195\n",
      "first 5 words in filtered_words: ['slow-moving', 'aimless', 'movie', 'distressed', 'drifting']\n"
     ]
    }
   ],
   "source": [
    "filtered_words = np.array([i for i in range(len(D[0])) if num2word[i] not in STOP_WORDS]) # remove stop words\n",
    "print(f\"number of words after removing stop words: {len(filtered_words)}\")\n",
    "print(f'first 5 words in filtered_words: {[num2word[w] for w in filtered_words[:5]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f2cb90-eda2-4609-94cc-3470c428a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 most frequent words (stop words excluded): ['good', 'great', 'movie', 'phone', 'film']\n"
     ]
    }
   ],
   "source": [
    "filtered_words_sorted_by_freq = np.array([i for i in np.argsort(col_sums)[::-1] if i in filtered_words]) # descending\n",
    "print(f'top 5 most frequent words (stop words excluded): {[num2word[i] for i in filtered_words_sorted_by_freq[:5]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d254da7-2e44-47d3-9f7c-5a280135b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show first 5 features after sorting: [ 4  8  9 11 15]\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 2500\n",
    "features = filtered_words_sorted_by_freq[:TOP_N]\n",
    "features.sort()\n",
    "print(f'show first 5 features after sorting: {features[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70fd323-14ab-472b-9782-e4e68449baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (3000, 5195)\n",
      "x_reduced.shape = (3000, 2500)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(D)[:, filtered_words]\n",
    "x_reduced = np.array(D)[:, features]\n",
    "print(f'x.shape = {x.shape}')\n",
    "print(f'x_reduced.shape = {x_reduced.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0260d59-2922-429c-8459-6125ca702db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels: 3000\n",
      "first 5 labels: [0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([pair[1] for pair in data])\n",
    "print(f'number of labels: {len(labels)}')\n",
    "print(f'first 5 labels: {labels[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec13397-c2e6-4b5f-aa1b-09d3979c3540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_no_selection.shape = (2100, 5195)\n",
      "y_train_no_selection.shape = (2100,)\n",
      "x_val_no_selection.shape = (300, 5195)\n",
      "y_val_no_selection.shape = (300,)\n",
      "x_test_no_selection.shape = (600, 5195)\n",
      "y_test_no_selection.shape = (600,)\n",
      "\n",
      "x_train.shape = (2100, 2500)\n",
      "y_train.shape = (2100,)\n",
      "x_val.shape = (300, 2500)\n",
      "y_val.shape = (300,)\n",
      "x_test.shape = (600, 2500)\n",
      "y_test.shape = (600,)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% - 10% - 20% split (no feature selection)\n",
    "(\n",
    "    x_train_val_no_selection, \n",
    "    x_test_no_selection, \n",
    "    y_train_val_no_selection, \n",
    "    y_test_no_selection \n",
    ") = train_test_split(x, labels, test_size=0.2, random_state=1)\n",
    "(\n",
    "    x_train_no_selection, \n",
    "    x_val_no_selection, \n",
    "    y_train_no_selection, \n",
    "    y_val_no_selection\n",
    ") = train_test_split(x_train_val_no_selection, y_train_val_no_selection, test_size=0.125, random_state=1)\n",
    "print(f'x_train_no_selection.shape = {x_train_no_selection.shape}')\n",
    "print(f'y_train_no_selection.shape = {y_train_no_selection.shape}')\n",
    "print(f'x_val_no_selection.shape = {x_val_no_selection.shape}')\n",
    "print(f'y_val_no_selection.shape = {y_val_no_selection.shape}')\n",
    "print(f'x_test_no_selection.shape = {x_test_no_selection.shape}')\n",
    "print(f'y_test_no_selection.shape = {y_test_no_selection.shape}')\n",
    "print()\n",
    "\n",
    "# 70% - 10% - 20% split (with feature selection)\n",
    "(\n",
    "    x_train_val, \n",
    "    x_test, \n",
    "    y_train_val, \n",
    "    y_test \n",
    ") = train_test_split(x_reduced, labels, test_size=0.2, random_state=1)\n",
    "(\n",
    "    x_train, \n",
    "    x_val, \n",
    "    y_train, \n",
    "    y_val \n",
    ") = train_test_split(x_train_val, y_train_val, test_size=0.125, random_state=1)\n",
    "print(f'x_train.shape = {x_train.shape}')\n",
    "print(f'y_train.shape = {y_train.shape}')\n",
    "print(f'x_val.shape = {x_val.shape}')\n",
    "print(f'y_val.shape = {y_val.shape}')\n",
    "print(f'x_test.shape = {x_test.shape}')\n",
    "print(f'y_test.shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33889beb-c0b7-4110-a9dc-8acece5d70a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[decision tree classifier (no feature selection)]\n",
      "\n",
      "accuracy on validation dataset = 72.0%\n",
      "offline efficiency cost = 2041 ms\n",
      "online efficiency cost = 9 us\n",
      "\n",
      "[decision tree classifier (with feature selection)]\n",
      "\n",
      "accuracy on validation dataset = 77.0%\n",
      "offline efficiency cost = 780 ms\n",
      "online efficiency cost = 5 us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "tree1 = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "tree1.fit(x_train_no_selection, y_train_no_selection)\n",
    "build_time1 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "pred = tree1.predict(x_val_no_selection)\n",
    "classify_time1 = time.time() - start_time\n",
    "\n",
    "print('[decision tree classifier (no feature selection)]')\n",
    "print()\n",
    "print(f'accuracy on validation dataset = {round(accuracy_score(y_val_no_selection, pred) * 100, 2)}%')\n",
    "print(f'offline efficiency cost = {round(build_time1 * 1000)} ms')\n",
    "print(f'online efficiency cost = {round(classify_time1 / len(y_val_no_selection) * 10 ** 6)} us')\n",
    "print()\n",
    "\n",
    "tree2 = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "tree2.fit(x_train, y_train)\n",
    "build_time2 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "pred = tree2.predict(x_val)\n",
    "classify_time2 = time.time() - start_time\n",
    "\n",
    "print('[decision tree classifier (with feature selection)]')\n",
    "print()\n",
    "print(f'accuracy on validation dataset = {round(accuracy_score(y_val, pred) * 100, 2)}%')\n",
    "print(f'offline efficiency cost = {round(build_time2 * 1000)} ms')\n",
    "print(f'online efficiency cost = {round(classify_time2 / len(y_val) * 10 ** 6)} us')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "108819b6-ef6a-4d61-af2f-920a0421e263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[decision tree classifier (no feature selection)] accuracy on testing dataset = 73.83%\n",
      "[decision tree classifier (with feature selection)] accuracy on testing dataset = 75.67%\n"
     ]
    }
   ],
   "source": [
    "print(f'[decision tree classifier (no feature selection)] accuracy on testing dataset = {round(accuracy_score(y_test_no_selection, tree1.predict(x_test_no_selection)) * 100, 2)}%')\n",
    "print(f'[decision tree classifier (with feature selection)] accuracy on testing dataset = {round(accuracy_score(y_test, tree2.predict(x_test)) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab14d64-428d-4316-aa70-961952079bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[knn classifier (scikit-learn, no feature selection)] accuracy on validation dataset = 75.33%\n",
      "[knn classifier (scikit-learn, with feature selection)] accuracy on validation dataset = 75.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "K = 11\n",
    "knn1 = KNeighborsClassifier(n_neighbors=K, metric='cosine')\n",
    "knn1.fit(x_train_no_selection, y_train_no_selection)\n",
    "print(f'[knn classifier (scikit-learn, no feature selection)] accuracy on validation dataset = {round(accuracy_score(y_val_no_selection, knn1.predict(x_val_no_selection)) * 100, 2)}%')\n",
    "knn2 = KNeighborsClassifier(n_neighbors=K, metric='cosine')\n",
    "knn2.fit(x_train, y_train)\n",
    "print(f'[knn classifier (scikit-learn, with feature selection)] accuracy on validation dataset = {round(accuracy_score(y_val, knn2.predict(x_val)) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6eb78-b9da-47f7-bec4-eec6a2d026df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'[knn classifier (scikit-learn, no feature selection)] accuracy on testing dataset = {round(accuracy_score(y_test_no_selection, knn1.predict(x_test_no_selection)) * 100, 2)}%')\n",
    "print(f'[knn classifier (scikit-learn, with feature selection)] accuracy on testing dataset = {round(accuracy_score(y_test, knn2.predict(x_test)) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16e6d7-e04b-402c-9e6a-e5a763da6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKNN:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.k = n_neighbors\n",
    "        self.x_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = np.zeros(len(x))\n",
    "\n",
    "        for i, v in enumerate(x):\n",
    "            dist_arr = np.zeros(len(self.x_train))\n",
    "            \n",
    "            for j, instance in enumerate(self.x_train):\n",
    "                dist_arr[j] = 1 - self.get_sim(v, instance)\n",
    "\n",
    "            top_k = self.y_train[np.argsort(dist_arr)[:self.k]]\n",
    "            one_count = np.count_nonzero(top_k)\n",
    "            zero_count = self.k - one_count\n",
    "            pred[i] = 1 if one_count >= zero_count else 0\n",
    "\n",
    "        return pred\n",
    "\n",
    "    # cosine similarity\n",
    "    def get_sim(self, v1, v2):\n",
    "        norm1 = np.linalg.norm(v1)\n",
    "        norm2 = np.linalg.norm(v2)\n",
    "\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            return 0\n",
    "            \n",
    "        return v1.dot(v2) / (norm1 * norm2)\n",
    "\n",
    "knn3 = MyKNN(n_neighbors=K)\n",
    "\n",
    "start_time = time.time()\n",
    "knn3.fit(x_train_no_selection, y_train_no_selection)\n",
    "build_time3 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "pred = knn3.predict(x_val_no_selection)\n",
    "classify_time3 = time.time() - start_time\n",
    "\n",
    "print('[knn classifier (my implementation, no feature selection)]')\n",
    "print()\n",
    "print(f'accuracy on validation dataset = {round(accuracy_score(y_val_no_selection, pred) * 100, 2)}%')\n",
    "print(f'offline efficiency cost = {round(build_time3 * 10 ** 6)} us')\n",
    "print(f'online efficiency cost = {round(classify_time3 / len(y_val_no_selection) * 1000)} ms')\n",
    "print()\n",
    "\n",
    "knn4 = MyKNN(n_neighbors=K)\n",
    "\n",
    "start_time = time.time()\n",
    "knn4.fit(x_train, y_train)\n",
    "build_time4 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "pred = knn4.predict(x_val)\n",
    "classify_time4 = time.time() - start_time\n",
    "\n",
    "print('[knn classifier (my implementation, with feature selection)]')\n",
    "print()\n",
    "print(f'accuracy on validation dataset = {round(accuracy_score(y_val, pred) * 100, 2)}%')\n",
    "print(f'offline efficiency cost = {round(build_time4 * 10 ** 6)} us')\n",
    "print(f'online efficiency cost = {round(classify_time4 / len(y_val) * 1000)} ms')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08464802-67bd-45e6-97a1-f310d7a6b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'[knn classifier (my implementation, no feature selection)] accuracy on testing dataset = {round(accuracy_score(y_test_no_selection, knn1.predict(x_test_no_selection)) * 100, 2)}%')\n",
    "print(f'[knn classifier (my implementation, with feature selection)] accuracy on testing dataset = {round(accuracy_score(y_test, knn2.predict(x_test)) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce0fab-8a5a-4163-bb0a-1ce82bb7ffdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
