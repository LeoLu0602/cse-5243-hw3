{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20918e76-b109-494a-8cd1-135d67e6551c",
   "metadata": {},
   "source": [
    "# HW#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc8bbee-618f-46ab-85ea-e4325e4a0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# converts a txt file to the form of [string, int][]\n",
    "def clean(path):\n",
    "    res = []\n",
    "    \n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            words = line.split()\n",
    "            # remove all leading and trailing nonalphabetic characters in each word and transform into lowercase\n",
    "            # ex: -I'm, -> i'm\n",
    "            sentence = ' '.join([re.sub(r'^[^a-zA-Z]+|[^a-zA-Z]+$','' , word).lower() for word in words[:-1]])\n",
    "            label = int(words[-1])\n",
    "            res.append([sentence, label])\n",
    "\n",
    "    return res\n",
    "\n",
    "# gives each word an unique number (starting from 0)\n",
    "def encode(words):\n",
    "    res = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in res:\n",
    "            res[word] = len(res)\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "def construct_matrix(sentences, word2num):\n",
    "    M = len(sentences)\n",
    "    N = len(word2num)\n",
    "    res = [[0] * N for i in range(M)]\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in sentence.split():\n",
    "            res[i][word2num[word]] += 1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239d23cb-f99f-451e-9670-11bb1711b716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "['a very very very slow-moving aimless movie about a distressed drifting young man', 0]\n"
     ]
    }
   ],
   "source": [
    "# get all txt files under ./data except for readme.txt\n",
    "FILES = [os.path.join('./data', f) for f in os.listdir('./data') if f.endswith('.txt') and f != 'readme.txt']\n",
    "data = []\n",
    "\n",
    "for file in FILES:\n",
    "    data += clean(file)\n",
    "\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03fb9bc-511d-48dd-ab47-4f71e6c0aac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5339\n",
      "[('a', 0), ('very', 1), ('slow-moving', 2), ('aimless', 3), ('movie', 4)]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for x in data:\n",
    "    for word in x[0].split():\n",
    "        words.append(word)\n",
    "\n",
    "word2num = encode(words)\n",
    "\n",
    "print(len(word2num))\n",
    "print([(word, num) for word, num in word2num.items() if num < 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14f0214-fe35-443b-97c2-4b5102df0bba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 5339\n",
      "[2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "D = construct_matrix([x[0] for x in data], word2num)\n",
    "\n",
    "print(len(D), len(D[0]))\n",
    "print(D[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04e28f-8a04-4348-8a2b-1c688d55bcec",
   "metadata": {},
   "source": [
    "# HW#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ccdf508-ffff-4ea8-a1c8-b7f4c220925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 columns sums: [886 243   1   1 177  85   1   1   4  14]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "col_sums = np.sum(np.array(D), axis=0)\n",
    "print(f'First 10 columns sums: {col_sums[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abf883bd-e5e3-45c6-ac2a-01651cfe67c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 stop words: ['which', 'having', 'while', \"you'll\", 'is', 'i', 'are', 'will', 'than', \"won't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kennycartman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "print(f'10 stop words: {list(STOP_WORDS)[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "075b2282-bde1-46d3-b04a-6360956bf5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words (in number): [ 16  32  77   0  57  50  75 117  23  13]\n",
      "Top 10 most frequent words: [num2word[w] for w in words_sorted_by_freq[:10]]\"\n"
     ]
    }
   ],
   "source": [
    "words_sorted_by_freq = np.argsort(col_sums)[::-1] # descending order\n",
    "print(f'Top 10 most frequent words (in number): {words_sorted_by_freq[:10]}') # number form\n",
    "print(f'Top 10 most frequent words: [num2word[w] for w in words_sorted_by_freq[:10]]\"') # word form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab76e2be-e133-44ff-b6f2-d7c5f34f8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num2word's size = 5339\n",
      "First 5 entries in num2word: [(0, 'a'), (1, 'very'), (2, 'slow-moving'), (3, 'aimless'), (4, 'movie')]\n"
     ]
    }
   ],
   "source": [
    "num2word = {num: word for word, num in word2num.items()}\n",
    "print(f'num2word\\'s size = {len(num2word)}')\n",
    "print(f'First 5 entries in num2word: {[(num, word) for num, word in num2word.items() if num < 5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71f2cb90-eda2-4609-94cc-3470c428a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words (stop words removed) = 5195\n",
      "Top 10 most frequent words (in number, stop words removed): [87, 455, 4, 4412, 147, 231, 3181, 314, 1600, 250]\n",
      "Top 10 most frequent words (stop words removed): ['good', 'great', 'movie', 'phone', 'film', 'one', 'food', 'like', 'place', 'time']\n"
     ]
    }
   ],
   "source": [
    "filtered_words_sorted_by_freq = [int(w) for w in words_sorted_by_freq if num2word[int(w)] not in STOP_WORDS] # remove stop words\n",
    "print(f'Number of words (stop words removed) = {len(filtered_words_sorted_by_freq)}')\n",
    "print(f'Top 10 most frequent words (in number, stop words removed): {filtered_words_sorted_by_freq[:10]}') # number form\n",
    "print(f'Top 10 most frequent words (stop words removed): {[num2word[w] for w in filtered_words_sorted_by_freq[:10]]}') # word form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d254da7-2e44-47d3-9f7c-5a280135b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show first 10 feature: [87, 455, 4, 4412, 147, 231, 3181, 314, 1600, 250]\n",
      "Show first 10 feature after sorting: [4, 8, 9, 11, 15, 17, 18, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "K = 1000\n",
    "features = filtered_words_sorted_by_freq[:K]\n",
    "print(f'Show first 10 feature: {features[:10]}')\n",
    "features.sort()\n",
    "print(f'Show first 10 feature after sorting: {features[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c70fd323-14ab-472b-9782-e4e68449baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows (after feature selection) = 3000\n",
      "Number of columns (after feature selection) = 1000\n",
      "First 10 columns sums of D_reduced: [177   4  14  16   9   4  35   5   4   9]\n",
      "First 10 entries of the first row of D_reduced: [1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "D_reduced = np.array(D)[:, features]\n",
    "print(f'Number of rows (after feature selection) = {len(D_reduced)}')\n",
    "print(f'Number of columns (after feature selection) = {len(D_reduced[0])}')\n",
    "print(f'First 10 columns sums of D_reduced: {np.sum(np.array(D_reduced), axis=0)[:10]}')\n",
    "print(f'First 10 entries of the first row of D_reduced: {D_reduced[0][:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0260d59-2922-429c-8459-6125ca702db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of labels = 3000\n",
      "First 10 labels: [0, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "labels = [pair[1] for pair in data]\n",
    "print(f'Size of labels = {len(labels)}')\n",
    "print(f'First 10 labels: {labels[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ec13397-c2e6-4b5f-aa1b-09d3979c3540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_train = 2100\n",
      "Size of y_train = 2100\n",
      "Size of x_val = 300\n",
      "Size of y_val = 300\n",
      "Size of x_test = 600\n",
      "Size of y_test = 600\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# 70% - 10% - 20% split\n",
    "p = math.floor(0.7 * len(D))\n",
    "q = math.floor(0.1 * len(D))\n",
    "x_train = D[:p] \n",
    "y_train = labels[:p]\n",
    "x_val = D[p: p + q]\n",
    "y_val = labels[p: p + q]\n",
    "x_test = D[p + q:]\n",
    "y_test = labels[p + q:]\n",
    "print(f'Size of x_train = {len(x_train)}')\n",
    "print(f'Size of y_train = {len(y_train)}')\n",
    "print(f'Size of x_val = {len(x_val)}')\n",
    "print(f'Size of y_val = {len(y_val)}')\n",
    "print(f'Size of x_test = {len(x_test)}')\n",
    "print(f'Size of y_test = {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33889beb-c0b7-4110-a9dc-8acece5d70a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Classifier 1: Decision Tree Classifier] Accuracy on validation dataset = 73.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree = tree.fit(x_train, y_train)\n",
    "y_pred = tree.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'[Classifier 1: Decision Tree Classifier] Accuracy on validation dataset = {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108819b6-ef6a-4d61-af2f-920a0421e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'[Classifier 1: Decision Tree Classifier] Accuracy on validation dataset = {round(accuracy * 100, 2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
