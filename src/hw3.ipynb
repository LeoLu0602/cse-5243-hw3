{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20918e76-b109-494a-8cd1-135d67e6551c",
   "metadata": {},
   "source": [
    "# HW#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc8bbee-618f-46ab-85ea-e4325e4a0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# converts a txt file to the form of [string, int][]\n",
    "def clean(path):\n",
    "    res = []\n",
    "    \n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            words = line.split()\n",
    "            # remove all leading and trailing nonalphabetic characters in each word and transform into lowercase\n",
    "            # ex: -I'm, -> i'm\n",
    "            sentence = ' '.join([re.sub(r'^[^a-zA-Z]+|[^a-zA-Z]+$','' , word).lower() for word in words[:-1]])\n",
    "            label = int(words[-1])\n",
    "            res.append([sentence, label])\n",
    "\n",
    "    return res\n",
    "\n",
    "# gives each word an unique number (starting from 0)\n",
    "def encode(words):\n",
    "    res = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in res:\n",
    "            res[word] = len(res)\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "def construct_matrix(sentences, word2num):\n",
    "    M = len(sentences)\n",
    "    N = len(word2num)\n",
    "    res = [[0] * N for i in range(M)]\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in sentence.split():\n",
    "            res[i][word2num[word]] += 1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239d23cb-f99f-451e-9670-11bb1711b716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "['a very very very slow-moving aimless movie about a distressed drifting young man', 0]\n"
     ]
    }
   ],
   "source": [
    "# get all txt files under ./data except for readme.txt\n",
    "FILES = [os.path.join('./data', f) for f in os.listdir('./data') if f.endswith('.txt') and f != 'readme.txt']\n",
    "data = []\n",
    "\n",
    "for file in FILES:\n",
    "    data += clean(file)\n",
    "\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03fb9bc-511d-48dd-ab47-4f71e6c0aac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5339\n",
      "[('a', 0), ('very', 1), ('slow-moving', 2), ('aimless', 3), ('movie', 4)]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for x in data:\n",
    "    for word in x[0].split():\n",
    "        words.append(word)\n",
    "\n",
    "word2num = encode(words)\n",
    "\n",
    "print(len(word2num))\n",
    "print([(word, num) for word, num in word2num.items() if num < 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14f0214-fe35-443b-97c2-4b5102df0bba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 5339\n",
      "[2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "D = construct_matrix([x[0] for x in data], word2num)\n",
    "\n",
    "print(len(D), len(D[0]))\n",
    "print(D[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04e28f-8a04-4348-8a2b-1c688d55bcec",
   "metadata": {},
   "source": [
    "# HW#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ccdf508-ffff-4ea8-a1c8-b7f4c220925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 columns sums: [886 243   1   1 177  85   1   1   4  14]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "col_sums = np.sum(np.array(D), axis=0)\n",
    "print(f'First 10 columns sums: {col_sums[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf883bd-e5e3-45c6-ac2a-01651cfe67c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 stop words: ['both', 'whom', 'until', \"couldn't\", 'while', 'each', 'above', \"doesn't\", 'he', \"that'll\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kennycartman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "print(f'10 stop words: {list(STOP_WORDS)[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075b2282-bde1-46d3-b04a-6360956bf5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words (in number): [ 16  32  77   0  57  50  75 117  23  13]\n",
      "Top 10 most frequent words: [num2word[w] for w in words_sorted_by_freq[:10]]\"\n"
     ]
    }
   ],
   "source": [
    "words_sorted_by_freq = np.argsort(col_sums)[::-1] # descending order\n",
    "print(f'Top 10 most frequent words (in number): {words_sorted_by_freq[:10]}') # number form\n",
    "print(f'Top 10 most frequent words: [num2word[w] for w in words_sorted_by_freq[:10]]\"') # word form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab76e2be-e133-44ff-b6f2-d7c5f34f8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num2word's size = 5339\n",
      "First 5 entries in num2word: [(0, 'a'), (1, 'very'), (2, 'slow-moving'), (3, 'aimless'), (4, 'movie')]\n"
     ]
    }
   ],
   "source": [
    "num2word = {num: word for word, num in word2num.items()}\n",
    "print(f'num2word\\'s size = {len(num2word)}')\n",
    "print(f'First 5 entries in num2word: {[(num, word) for num, word in num2word.items() if num < 5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f2cb90-eda2-4609-94cc-3470c428a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words (stop words removed) = 5195\n",
      "Top 10 most frequent words (in number, stop words removed): [87, 455, 4, 4412, 147, 231, 3181, 314, 1600, 250]\n",
      "Top 10 most frequent words (stop words removed): ['good', 'great', 'movie', 'phone', 'film', 'one', 'food', 'like', 'place', 'time']\n"
     ]
    }
   ],
   "source": [
    "filtered_words_sorted_by_freq = [int(w) for w in words_sorted_by_freq if num2word[int(w)] not in STOP_WORDS] # remove stop words\n",
    "print(f'Number of words (stop words removed) = {len(filtered_words_sorted_by_freq)}')\n",
    "print(f'Top 10 most frequent words (in number, stop words removed): {filtered_words_sorted_by_freq[:10]}') # number form\n",
    "print(f'Top 10 most frequent words (stop words removed): {[num2word[w] for w in filtered_words_sorted_by_freq[:10]]}') # word form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d254da7-2e44-47d3-9f7c-5a280135b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show first 10 feature: [87, 455, 4, 4412, 147, 231, 3181, 314, 1600, 250]\n",
      "Show first 10 feature after sorting: [4, 8, 9, 11, 15, 17, 18, 20, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "K = 1000\n",
    "features = filtered_words_sorted_by_freq[:K]\n",
    "print(f'Show first 10 feature: {features[:10]}')\n",
    "features.sort()\n",
    "print(f'Show first 10 feature after sorting: {features[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70fd323-14ab-472b-9782-e4e68449baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows (after feature selection) = 3000\n",
      "Number of columns (after feature selection) = 1000\n",
      "First 10 columns sums of D_reduced: [177   4  14  16   9   4  35   5   4   9]\n",
      "First 10 entries of the first row of D_reduced: [1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "D_reduced = np.array(D)[:, features]\n",
    "print(f'Number of rows (after feature selection) = {len(D_reduced)}')\n",
    "print(f'Number of columns (after feature selection) = {len(D_reduced[0])}')\n",
    "print(f'First 10 columns sums of D_reduced: {np.sum(np.array(D_reduced), axis=0)[:10]}')\n",
    "print(f'First 10 entries of the first row of D_reduced: {D_reduced[0][:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0260d59-2922-429c-8459-6125ca702db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of labels = 3000\n",
      "First 10 labels: [0, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "labels = [pair[1] for pair in data]\n",
    "print(f'Size of labels = {len(labels)}')\n",
    "print(f'First 10 labels: {labels[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec13397-c2e6-4b5f-aa1b-09d3979c3540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train = (2100, 1000)\n",
      "Shape of y_train = (2100,)\n",
      "Shape of x_val = (300, 1000)\n",
      "Shape of y_val = (300,)\n",
      "Shape of x_test = (600, 1000)\n",
      "Shape of y_test = (600,)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% - 10% - 20% split\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(np.array(D_reduced), np.array(labels), test_size=0.2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.125)\n",
    "print(f'Shape of x_train = {x_train.shape}')\n",
    "print(f'Shape of y_train = {y_train.shape}')\n",
    "print(f'Shape of x_val = {x_val.shape}')\n",
    "print(f'Shape of y_val = {y_val.shape}')\n",
    "print(f'Shape of x_test = {x_test.shape}')\n",
    "print(f'Shape of y_test = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33889beb-c0b7-4110-a9dc-8acece5d70a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Classifier 1: Decision Tree Classifier] Accuracy on validation dataset = 69.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree = tree.fit(x_train, y_train)\n",
    "y_pred = tree.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'[Classifier 1: Decision Tree Classifier] Accuracy on validation dataset = {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "108819b6-ef6a-4d61-af2f-920a0421e263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Classifier 1: Decision Tree Classifier] Accuracy on testing dataset = 78.0%\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'[Classifier 1: Decision Tree Classifier] Accuracy on testing dataset = {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ab14d64-428d-4316-aa70-961952079bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Classifier 2: KNN Classifier (scikit-learn)] Accuracy on validation dataset = 68.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "K = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=K)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'[Classifier 2: KNN Classifier (scikit-learn)] Accuracy on validation dataset = {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45b6eb78-b9da-47f7-bec4-eec6a2d026df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Classifier 2: KNN Classifier (scikit-learn)] Accuracy on testing dataset = 68.17%\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'[Classifier 2: KNN Classifier (scikit-learn)] Accuracy on testing dataset = {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb16e6d7-e04b-402c-9e6a-e5a763da6689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Classifier 3: KNN Classifier (my implementation)] Accuracy on validation dataset = 70.0%\n"
     ]
    }
   ],
   "source": [
    "class MyKNN:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        self.k = n_neighbors\n",
    "        self.x_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = np.array([])\n",
    "\n",
    "        for v in x:\n",
    "            sim_arr = np.array([])\n",
    "            \n",
    "            for i, instance in enumerate(x_train):\n",
    "                sim_arr = np.append(sim_arr, self.get_sim(v, instance))\n",
    "    \n",
    "            top_k = self.y_train[np.argsort(sim_arr)[::-1][:self.k]]\n",
    "            one_count = np.count_nonzero(top_k)\n",
    "            zero_count = self.k - one_count\n",
    "            \n",
    "            if one_count >= zero_count:\n",
    "                pred = np.append(pred, 1)\n",
    "            else:\n",
    "                pred = np.append(pred, 0)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    # cosine similarity\n",
    "    def get_sim(self, v1, v2):\n",
    "        norm1 = np.linalg.norm(v1)\n",
    "        norm2 = np.linalg.norm(v2)\n",
    "\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            return 0\n",
    "            \n",
    "        return v1.dot(v2) / (norm1 * norm2)\n",
    "\n",
    "knn = MyKNN(n_neighbors=K)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'[Classifier 3: KNN Classifier (my implementation)] Accuracy on validation dataset = {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08464802-67bd-45e6-97a1-f310d7a6b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'[Classifier 3: KNN Classifier (my implementation)] Accuracy on testing dataset = {round(accuracy * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c7142-94ba-48e2-80db-15d8105682b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
